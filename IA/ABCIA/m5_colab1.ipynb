{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vgamBRZseFEcE8iB02-SVmGWTuxp3Lzq","timestamp":1677874091864},{"file_id":"19zAbi_md7YZOOXuJiN4PxAQvZFnOwWFP","timestamp":1677246908566},{"file_id":"1YD5iAnahTbYV35FZB1DC9-19-_vke_ux","timestamp":1676604904967},{"file_id":"1M0Wf4I6-vn2HJm2f_pcpZK68MOoikx-l","timestamp":1676577930323}],"authorship_tag":"ABX9TyMvsnOSiflaJffofy2olofV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Exemplo de Classificação Básico: **Classificação de imagens** de roupas na escala de cinza\n","\n","\n","---\n","\n","\n","- Exemplo adotado no curso **ABCIA**\n","- Código baseado em: https://www.tensorflow.org/tutorials/keras/classification"],"metadata":{"id":"1jKD-NzDrv91"}},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Z7-AQATzrm4k"},"outputs":[],"source":["#@title MIT License\n","#\n","# Copyright (c) 2017 François Chollet\n","#\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."]},{"cell_type":"markdown","source":["# Neste exemplo veremos como treinar um modelo de uma rede neural para classificação de imagens de roupas, como tênis e camisetas.\n","\n","Usaremos o [tf.keras](https://www.tensorflow.org/guide/keras), uma API de alto-nível para construir e treinar modelos no TensorFlow.\n","\n","\n","\n","---\n","[<img src=\"https://www.gstatic.com/devrel-devsite/prod/vde5e97689c1d94fa683b9e5392f0f6b6562f68c8b527194cc7ca91d97bde649f/tensorflow/images/lockup.svg\">](http://www.tensorflow.org)\n"],"metadata":{"id":"6Q78HETdteO6"}},{"cell_type":"code","source":["#@title Importando Bibliotecas - TODO\n","--- TODO\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px"],"metadata":{"id":"hWQxYIXJsXzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Importando a base de dados Fashion MNIST\n","\n","# A base de dados Fashion MNIST pode ser obtida via API do Keras junto ao Tensorflow\n","# https://www.tensorflow.org/datasets/catalog/fashion_mnist?hl=pt-br\n","fashion_mnist = keras.datasets.fashion_mnist"],"metadata":{"id":"js33gITbu37N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Esse exemplo usa a base de dados Fashion MNIST que contém 70,000 imagens em tons de cinza em 10 categorias. As imagens mostram artigos individuais de roupas com baixa resolução, ou seja, 28 por 28 pixels."],"metadata":{"id":"wJgLnxv9wjIm"}},{"cell_type":"code","source":["#@title Carregando a base de dados - TODO\n","(train_images, train_labels), (test_images, test_labels) = TODO"],"metadata":{"id":"8DOsNhJX1cL4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cada exemplo da base de dados possui uma das seguintes labels:\n","<table>\n","  <tr>\n","    <th>Label</th>\n","    <th>Classe</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>Camisetas/Top (T-shirt/top)</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Calça (Trouser)</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Suéter (Pullover)</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Vestidos (Dress)</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Casaco (Coat)</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Sandálias (Sandal)</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Camisas (Shirt)</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Tênis (Sneaker)</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Bolsa (Bag)</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Botas (Ankle boot)</td>\n","  </tr>\n","</table>\n","\n","TL;DR\n","- Cada linha é uma image separada\n","- A Coluna 1 é a label correspondente.\n","- As colunas restantes são números de pixels (784 no total).\n","- Cada valor é a escuridão do pixel (1 a 255)\n"],"metadata":{"id":"5jUkjY383Wyb"}},{"cell_type":"markdown","source":["A pós carregar a base de dados com a função `load_data()` são retornados quatro NumPy arrays:\n","\n","* Os *arrays* `train_images` e `train_labels`  são o *conjunto de treinamento*— os dados do modelo usados para aprender.\n","* O modelo é testado com o *conjunto de teste*, os *arrays* `test_images` e `test_labels`.\n","\n","As imagens são arrays  NumPy de 28x28, com os valores de pixels entre 0 to 255. As *labels* (alvo da classificação) são um  array  de inteiros, no intervalo de  0 a 9."],"metadata":{"id":"-h0UVpS_yENW"}},{"cell_type":"code","source":["# 60,000 imagens (no tamanho de 28x28) para treinar a nossa rede\n","train_images.shape"],"metadata":{"id":"5Dk4-cukx3ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 10,000 imagens (no tamanho de 28x28) para testar a nossa rede\n","test_images.shape"],"metadata":{"id":"cMzqHSoMyMDR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://github.com/zalandoresearch/fashion-mnist#labels\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"],"metadata":{"id":"VIXB5VIoyep6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Visualização da base de dados\n","\"\"\"\n","Vamos exibir as primeiras 25 imagens do conjunto de treinamento e exibir \n","o nome da classe abaixo de cada imagem.\n","\"\"\"\n","\n","plt.figure(figsize=(10,10))\n","\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[train_labels[i]])\n","plt.show()"],"metadata":{"id":"MqZviT0h5WuK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pré-processamento dos dados\n","\n","Os dados precisam ser pré-processados antes de treinar a rede. Conforme inspecionado a primeira imagem do conjunto de treinamento, observa-se que os valores dos **pixels estão entre 0 e 255**. \n","\n","Não sabemos a melhor maneira (sem um estudo preliminar) de dimensionar os valores dos pixel para modelagem para a rede neural, mas sabemos que algum dimensionamento é necessário.\n","\n","Um bom ponto de partida é normalizar os valores de pixel das imagens em tons de cinza, por exemplo, redimensioná-los para o intervalo `[0,1]`. Isso envolve primeiro converter o tipo de dados de inteiros não assinados em flutuantes e, em seguida, dividir os valores de pixel pelo valor máximo. É importante que o *conjunto de treinamento* e o *conjunto de teste* podem ser pré-processados do mesmo modo:"],"metadata":{"id":"xaeUqKEHavNf"}},{"cell_type":"code","source":["# Remodelando a matriz para 4 dims para que ela possa funcionar com a API Keras\n","bkp_ori_shape_train = train_images.shape\n","bkp_ori_shape_test = test_images.shape\n","\n","train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n","test_images  = test_images.reshape(test_images.shape[0], 28, 28, 1)\n","print(\"Shape train: \", train_images.shape)\n","print(\"Shape test : \", test_images.shape)\n","input_shape = (28, 28, 1)\n","\n","# Converter o tipo de dados de inteiros não assinados em flutuantes\n","train_norm = train_images.astype('float32')\n","test_norm = test_images.astype('float32')\n","\n","# Normalizando os códigos RGB dividindo-os para o valor RGB máximo - TODO\n","---- TODO"],"metadata":{"id":"_sHxUeOmmpIZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para verificar que os dados estão no formato correto e que estamos prontos para construir e treinar a rede, vamos mostrar uma imagem do **conjunto de treinamento** com os valores normalizados."],"metadata":{"id":"CqOuNi5udkbt"}},{"cell_type":"code","source":["# Reshape para visualizar a primeira imagem\n","fisrt_train_norm = train_norm[0].reshape(28,28)\n","\n","# Visualizando os valores de cada posição de pixel da imagem\n","fig = px.imshow(fisrt_train_norm, text_auto=True, color_continuous_scale='Greys')\n","fig.show()"],"metadata":{"id":"gaK-d153awl-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Construindo o modelo de classificação\n","\n","Construir a rede neural requer configurar as camadas do modelo, e depois, compilar o modelo."],"metadata":{"id":"Z-RrIR5geYIB"}},{"cell_type":"markdown","source":["### Configurando as camadas\n","\n","O principal bloco de construção da rede neural é a camada (*layer*). As camadas (*layers*) extraem representações dos dados inseridos na rede, onde essas representações são significativas para o problema à mão.\n","\n","Muito do *deep learning* consiste em encadear simples camadas. Muitas camadas, como `tf.keras.layers.Dense`, tem parâmetros que são aprendidos durante o treinamento.\n","\n","<center>\n","<img src=\"https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/74_blog_image_1.png\">(https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-4-full-connection)\n","</center>"],"metadata":{"id":"lBPAlpime2Wm"}},{"cell_type":"code","source":["# Modelo baseado em: \n","# https://www.kaggle.com/code/rutvikdeshpande/fashion-mnist-cnn-beginner-98/notebook\n","\n","model = keras.Sequential(\n","    [\n","    keras.layers.Conv2D(\n","        filters=8,\n","        kernel_size=5,\n","        padding='same',\n","        activation='relu',\n","        input_shape = input_shape),\n","    keras.layers.MaxPooling2D(\n","        pool_size=2, \n","        strides=2), # diminuição das amostras de 28*28 para 14*14\n","    keras.layers.Conv2D(\n","        filters=16,\n","        kernel_size=5,\n","        padding='same',\n","        activation='relu'),\n","    keras.layers.MaxPooling2D(\n","        pool_size=2, \n","        strides=2), # diminuição das amostras de 14*14 para 7*7\n","    # TODO\n","    --- TODO\n","    ]\n",")"],"metadata":{"id":"GCgqlgvVd-A4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explicação das camadas\n","\n","A **camada da rede**, `tf.keras.layers.Flatten`, exemplo: transforma o formato da imagem de um array de imagens de duas dimensões (de 28 por 28 pixels) para um array de uma dimensão (de 28 * 28 = 784 pixels). Pense nessa camada como camadas não empilhadas de pixels de uma imagem e os enfilere. Essa camada não tem parâmetros para aprender; ela só reformata os dados.\n","\n","<center>\n","<img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/flattening.png\"> \n","(http://www.tensorflow.org)\n","</center>\n","\n","Depois dos pixels serem achatados (*Flatten*), a rede consiste de uma sequência de duas camadas `tf.keras.layers.Dense` que são camadas neurais *densely connected*, ou *fully connected*:\n","- A **primeira camada da rede**, camada `Dense`, tem 120 nós (ou neurônios). \n","- A **segunda camada da rede** camada `Dense`, tem 84 nós (ou neurônios).\n","- A **terceira camada da rede** camada `Dense` é uma *softmax*  de 10 nós que retorna um array de `10 probabilidades`, cuja soma resulta em 1. Cada nó contém um valor que indica a probabilidade de que aquela **imagem pertence a uma das 10 classes**`\n","\n"],"metadata":{"id":"RCupo8JsfkSq"}},{"cell_type":"code","source":["!pip install visualkeras"],"metadata":{"id":"epefBAUfxJRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import visualkeras\n","visualkeras.layered_view(model)"],"metadata":{"id":"XMNHHClhw9Oa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Compilando o modelo\n","\n","Antes do modelo estar pronto para o treinamento, é necessário algumas configurações a mais. Essas serão adicionadas no passo de *compilação*:\n","\n","* *Função Loss* (`loss='sparse_categorical_crossentropy'`): essa mede quão precisa o modelo é durante o treinamento. Queremos minimizar a função para *guiar* o modelo para a direção certa.\n","* *Optimizer* (`optimizer='adam'`): isso é como o modelo se atualiza com base no dado que ele vê e sua função *loss*.\n","* *Métricas* (`metrics=['accuracy']`): usadas para monitorar os passos de treinamento e teste. O exemplo abaixo usa a *acurácia*, a fração das imagens que foram classificadas corretamente."],"metadata":{"id":"zxnZt_gAj6O9"}},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"QpFYVeYRfixg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Treinando o modelo\n","\n","Treinar a rede neural requer os seguintes passos:\n","\n","1. Alimente com os dados de treinamento, o modelo. Neste exemplo, os dados de treinamento são os arrays `train_norm` e `train_labels`.\n","2. O modelo aprende como associar as imagens as *labels*, uma das 10 possibilidades.\n","3. Perguntamos ao modelo para fazer previsões sobre o conjunto de teste — nesse exemplo, o array `test_norm`. Verificamos se as previsões combinaram com as *labels*  do array `test_labels`.\n","\n","Para começar a treinar, chame o método `model.fit`— assim chamado, porque ele \"encaixa\" o modelo no conjunto de treinamento. \n","\n","À medida que o modelo treina, as métricas loss e acurácia são mostradas. O modelo atinge uma acurácia maior que 0.80 (ou maior que 80%) com o conjunto de treinamento."],"metadata":{"id":"ru9hr8opl6yU"}},{"cell_type":"code","source":["# FIT - TODO\n","--- TODO"],"metadata":{"id":"BShSPc7Zka2M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Avaliando a acurácia do modelo\n","\n","Comparando como o modelo performou com o conjunto de teste - :"],"metadata":{"id":"uorCo8FwoAmO"}},{"cell_type":"code","source":["# Curva de aprendizagem\n","\n","loss_train = history_train.history['loss']\n","loss_val   = history_train.history['val_loss']\n","\n","epochs = range(1,5)\n","\n","plt.plot(epochs, loss_train, 'o', label='Training loss')\n","plt.plot(epochs, loss_val, 'r', label='validation loss')\n","\n","plt.title('Learning Curves - Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"H1aLPctowfdz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Curva de aprendizagem\n","\n","loss_train = history_train.history['accuracy']\n","loss_val   = history_train.history['val_accuracy']\n","\n","epochs = range(1,5)\n","\n","plt.plot(epochs, loss_train, 'o', label='Training Accuracy')\n","plt.plot(epochs, loss_val, 'r', label='Validation Accuracy')\n","\n","plt.title('Learning Curves - Training and Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"okBXu3UvhxiY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Acabou que o a acurácia com o conjunto de teste é um pouco menor do que a acurácia de treinamento. Essa diferença entre as duas acurácias representa um *overfitting*. Overfitting é modelo de aprendizado de máquina performou de maneira pior em um conjunto de entradas novas, e não usadas anteriormente, que usando o conjunto de treinamento."],"metadata":{"id":"DhNd267LpiJ-"}},{"cell_type":"code","source":["# Obter probabilidades da classificação - TODO\n","--- TODO"],"metadata":{"id":"QO2f2t-hbR4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Obter valores da classificação \n","correct = 0\n","\n","list_pred_argmax = []\n","for p in predictions:\n","  list_pred_argmax.append(np.argmax(p))\n","\n","list_pred_by_img = np.array(list_pred_argmax)\n","correct   = np.nonzero(list_pred_by_img == test_labels)[0]\n","incorrect = np.nonzero(list_pred_by_img != test_labels)[0]\n","print(\"Predições corretas  : \", len(correct))\n","print(\"Predições incorretas: \", len(incorrect))\n","\n","from sklearn.metrics import classification_report\n","\n","target_names = [\"Class {}\".format(i) for i in range(10)]\n","print(classification_report(test_labels, list_pred_by_img, target_names=target_names))\n"],"metadata":{"id":"iOTv_nxQgYuh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fazendo predições\n","\n","Com o modelo treinado, faremos a predições de algumas imagens."],"metadata":{"id":"vtMNrDKHpc-O"}},{"cell_type":"markdown","source":["Aqui, o modelo previu que a *label* de cada imagem no conjunto de treinamento. Vamos olhar o resultado da primeira predição:"],"metadata":{"id":"-tCoclrFp9Q4"}},{"cell_type":"code","source":["predictions[0]"],"metadata":{"id":"ngY7ydw6p3Uz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A predição é um array de 10 números. Eles representam a *confiança* do modelo que a imagem corresponde a cada um dos diferentes artigos de roupa. Podemos ver cada *label*  tem um maior valor de confiança. Então, o modelo é confiante de que esse imagem é uma bota (ankle boot) ou `class_names[9]`."],"metadata":{"id":"rhSpGdc-rGAk"}},{"cell_type":"markdown","source":["Vamos plotar algumas da previsão do modelo. Labels preditas corretamente são **azuis** e as predições erradas são **vermelhas**. Note que o modelo pode errar mesmo estando confiante."],"metadata":{"id":"qDAXaijOrvdC"}},{"cell_type":"code","source":["def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","\n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","\n","  if predicted_label == true_label:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","  predictions_array, true_label = predictions_array[i], true_label[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n","  plt.ylim([0, 1])\n","  predicted_label = np.argmax(predictions_array)\n","\n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('blue')"],"metadata":{"id":"MfzBO2d5sCPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_norm_no_shape = test_norm.reshape(bkp_ori_shape_test)\n","test_norm_no_shape.shape"],"metadata":{"id":"5ZlC4F4CH3eB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Colore as predições corretas de azul e as incorretas de vermelho.\n","\n","num_rows = 5\n","num_cols = 5\n","num_images = num_rows*num_cols\n","plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n","\n","for i in range(num_images):\n","  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","  plot_image(i, predictions, test_labels, test_norm_no_shape)\n","  \n","  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","  plot_value_array(i, predictions, test_labels)\n","plt.show()"],"metadata":{"id":"O9hABEacrWPF"},"execution_count":null,"outputs":[]}]}