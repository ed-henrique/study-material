{"cells":[{"cell_type":"markdown","metadata":{"id":"77gENRVX40S7"},"source":["# Exemplo de Classificação: **Classificação de imagens** de Cachorros e Gatos\n","\n","\n","---\n","\n","\n","- Exemplo adotado no curso **ABCIA**\n","- Código baseado em: https://www.tensorflow.org/tutorials/images/transfer_learning?hl=pt-br"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"d8jyt37T42Vf"},"outputs":[],"source":["#@title Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"aPxHdjwW5P2j"},"outputs":[],"source":["#@title MIT License\n","#\n","# Copyright (c) 2017 François Chollet                                                                                                                    # IGNORE_COPYRIGHT: cleared by OSS licensing\n","#\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbiEA1kBiZL9"},"outputs":[],"source":["#@title Verificando GPU\n","# Exemplo: Testa T4 - 16GB\n","# NVIDIA CUDA® cores: 2,560\n","# https://www.nvidia.com/pt-br/data-center/tesla-t4/\n","--------------- TODO"]},{"cell_type":"markdown","metadata":{"id":"hRTa3Ee15WsJ"},"source":["# Transferência de aprendizado e ajuste fino"]},{"cell_type":"markdown","metadata":{"id":"2X4KyhORdSeO"},"source":["Neste tutorial, você aprenderá a classificar imagens de cães e gatos usando o aprendizado de transferência de uma rede pré-treinada.\n","\n","Um modelo pré-treinado é uma rede salva que foi previamente treinada em um grande conjunto de dados, normalmente em uma tarefa de classificação de imagem em grande escala. Você usa o modelo pré-treinado como está ou usa o aprendizado de transferência para personalizar esse modelo para uma determinada tarefa.\n","\n","Você seguirá o fluxo de trabalho geral de aprendizado de máquina:\n","1.   Examinar e entender os dados\n","2.   Crie um pipeline de entrada, neste caso usando Keras ImageDataGenerator\n","3.   Definir o modelo \n","4.   Treine o modelo\n","5.   Avaliar modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqOt6Sv7AsMi"},"outputs":[],"source":["#@title Importes principais de bibliotecas\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","--------------- TODO\n"]},{"cell_type":"markdown","metadata":{"id":"0GoKGm1duzgk"},"source":["# Pré-processamento de dados\n","\n","Faça download e extraia um arquivo zip contendo as imagens e crie um `f.data.Dataset` para treinamento e validação usando o utilitário `tf.keras.utils.image_dataset_from_directory`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ro4oYaEmxe4r"},"outputs":[],"source":["SEED = 12\n","\n","!wget --no-check-certificate \\\n","    'https://www.dropbox.com/s/1wjwczpfddbbnb2/cat_and_dogs.zip' \\\n","    -O \"/tmp/cats-and-dogs.zip\"\n","\n","!unzip /tmp/cats-and-dogs.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHFgP1BTq6h6"},"outputs":[],"source":["train_dir = 'training_set/training_set'\n","validation_dir = 'training_set/training_set'\n","test_dir = 'test_set/test_set'\n","\n","BATCH_SIZE = 32\n","IMG_SIZE = (160, 160)\n","\n","# Imagens para treino do modelo\n","# Importante notar que estamos usando 85% dos dados para o treino\n","# e os dados restantes, ou seja, 15% para validação\n","--------------- TODO\n","(train_dir,\n","                                                            seed=SEED,\n","                                                            shuffle=True,\n","                                                            batch_size=BATCH_SIZE,\n","                                                            image_size=IMG_SIZE,\n","                                                            validation_split=0.15,\n","                                                            subset='training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cAvtLwi7_J__"},"outputs":[],"source":["# Imagens para validação do modelo\n","validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n","                                                                 shuffle=True,\n","                                                                 seed=SEED,\n","                                                                 batch_size=BATCH_SIZE,\n","                                                                 image_size=IMG_SIZE,\n","                                                                 validation_split=0.15,\n","                                                                 subset='validation')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wE-luogenP2q"},"outputs":[],"source":["# Imagens para teste do modelo\n","test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n","                                                                 shuffle=True,\n","                                                                 batch_size=BATCH_SIZE,\n","                                                                 image_size=IMG_SIZE,\n","                                                                 seed=SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5BeQyKThC_Y"},"outputs":[],"source":["#@title Visualizando algumas amostras do dataset\n","\n","class_names = train_dataset.class_names\n","\n","plt.figure(figsize=(10, 10))\n","for images, labels in train_dataset.take(1):\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(images[i].numpy().astype(\"uint8\"))\n","    plt.title(class_names[labels[i]])\n","    plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"MakSrdd--RKg"},"source":["### Configurar o conjunto de dados para desempenho\n","\n","Use a pré-busca em buffer para carregar imagens do disco sem que a E/S se torne um bloqueio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3UUPdm86LNC"},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"]},{"cell_type":"markdown","metadata":{"id":"MYfcVwYLiR98"},"source":["### Usar o aumento de dados\n","\n","Quando você não tem um grande conjunto de dados de imagem, é uma boa prática introduzir artificialmente a diversidade de amostra aplicando transformações aleatórias, porém realistas, às imagens de treinamento, como rotação e inversão horizontal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3P99QiMGit1A"},"outputs":[],"source":["--------------- TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQullOUHkm67"},"outputs":[],"source":["#@title Vamos aplicar repetidamente essas camadas na mesma imagem e ver o resultado.\n","for image, _ in train_dataset.take(1):\n","  plt.figure(figsize=(10, 10))\n","  first_image = image[0]\n","  for i in range(9):\n","    ax = plt.subplot(3, 3, i + 1)\n","    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n","    plt.imshow(augmented_image[0] / 255)\n","    plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"bAywKtuVn8uK"},"source":["### Redimensionar valores de pixel\n","\n","Em instantes, você fará o download do `tf.keras.applications.MobileNetV` para uso como modelo base. Este modelo espera valores de pixel em `[-1, 1]` , mas neste ponto, os valores de pixel em suas imagens estão em `[0, 255]`. Para redimensioná-los, use o método de pré-processamento incluído no modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cO0HM9JAQUFq"},"outputs":[],"source":["--------------- TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2NyJn4KQMux"},"outputs":[],"source":["# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling\n","rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"]},{"cell_type":"markdown","metadata":{"id":"OkH-kazQecHB"},"source":["## Crie o modelo base a partir dos convnets pré-treinados\n","\n","Você criará o modelo base a partir do modelo MobileNet V2 desenvolvido no Google. Isso é pré-treinado no conjunto de dados ImageNet, um grande conjunto de dados que consiste em `1,4 milhão de imagens e 1.000 classes`. \n","\n","Os recursos da última camada retêm mais generalidade. Primeiro, instancie um modelo MobileNet V2 pré-carregado com pesos treinados no ImageNet. Ao especificar o argumento `include_top=False`, você carrega uma rede que não inclui as camadas de classificação na parte superior, o que é ideal para extração de recursos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19IQ2gqneqmS"},"outputs":[],"source":["# Cria o modelo base a partir do modelo pré-treinado MobileNet V2\n","IMG_SHAPE = IMG_SIZE + (3,)\n","base_model = tf.keras.applications.MobileNetV2(\n","    input_shape = IMG_SHAPE,\n","    include_top = False,\n","    weights='imagenet'\n",")\n","--------------- TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-2LJL0EEUcx"},"outputs":[],"source":["image_batch, label_batch = next(iter(train_dataset))\n","feature_batch = base_model(image_batch)"]},{"cell_type":"markdown","metadata":{"id":"rlx56nQtfe8Y"},"source":["## Extração de recursos\n","\n","Nesta etapa, você congelará a base convolucional criada na etapa anterior e usará como extrator de recursos. Além disso, você adiciona um classificador em cima dele e treina o classificador de nível superior."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTCJH4bphOeo"},"outputs":[],"source":["base_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpbzSmPkDa-N"},"outputs":[],"source":["# Vamos dar uma olhada na arquitetura do modelo base\n","base_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"wdMRM8YModbk"},"source":["### Adicionar um cabeçalho de classificação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLnpMF5KOALm"},"outputs":[],"source":["global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","feature_batch_average = global_average_layer(feature_batch)\n","print(feature_batch_average.shape)"]},{"cell_type":"markdown","metadata":{"id":"O1p0OJBR6dOT"},"source":["Aplique uma camada `tf.keras.layers.Dense` para converter esses recursos em uma única previsão por imagem. Você não precisa de uma função de ativação aqui porque essa previsão será tratada como um logit ou um valor bruto de previsão. Números positivos predizem a classe 1, números negativos predizem a classe 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv4afXKj6cVa"},"outputs":[],"source":["--------------- TODO"]},{"cell_type":"markdown","metadata":{"id":"HXvz-ZkTa9b3"},"source":["Construa um modelo encadeando as camadas de aumento de dados, redimensionamento, `base_model` e extrator de recursos usando a API funcional do Keras. Como mencionado anteriormente, use `training=False` pois nosso modelo contém uma camada `BatchNormalization` (será executada no modo de inferência e não atualizará suas estatísticas de média e variação)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgzQX6Veb2WT"},"outputs":[],"source":["inputs = tf.keras.Input(shape=(160, 160, 3))\n","\n","x = data_augmentation(inputs)\n","x = preprocess_input(x)\n","x = base_model(x, training=False)\n","x = global_average_layer(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","\n","outputs = prediction_layer(x)\n","model = tf.keras.Model(inputs, outputs)"]},{"cell_type":"markdown","metadata":{"id":"g0ylJXE_kRLi"},"source":["### Compilar o modelo\n","\n","Compile o modelo antes de treiná-lo. Como existem duas classes, use a perda `tf.keras.losses.BinaryCrossentropy` com `from_logits=True`, pois o modelo fornece uma saída linear."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpR8HdyMhukJ"},"outputs":[],"source":["base_learning_rate = 0.0001\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8ARiyMFsgbH"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"RxvgOYTDSWTx"},"source":["### Treine o modelo\n","\n","Após treinar por 10 épocas, você deverá ver ~ 94% de precisão no conjunto de validação.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Om4O3EESkab1"},"outputs":[],"source":["initial_epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsaRFlZ9B6WK"},"outputs":[],"source":["--------------- TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53OTCh3jnbwV"},"outputs":[],"source":["#@title Curvas de aprendizado\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CqwV-CRdS6Nv"},"source":["## Afinação\n","\n","No experimento de extração de recursos, você estava treinando apenas algumas camadas em cima de um modelo base MobileNetV2. Os pesos da rede pré-treinada não foram atualizados durante o treinamento. \n","\n","Tudo o que você precisa fazer é descongelar o base_model e definir as camadas inferiores como não treináveis. Em seguida, você deve recompilar o modelo (necessário para que essas alterações tenham efeito) e retomar o treinamento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4nzcagVitLQm"},"outputs":[],"source":["base_model.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4HgVAacRs5v"},"outputs":[],"source":["# Vamos dar uma olhada para ver quantas camadas existem no modelo base\n","print(\"Number of layers in the base model: \", len(base_model.layers))\n","\n","# Ajuste fino desta camada em diante\n","fine_tune_at = 100\n","\n","# Congele todas as camadas antes da camada `fine_tune_at`\n","for layer in base_model.layers[:fine_tune_at]:\n","  layer.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"4Uk1dgsxT0IS"},"source":["### Compilar o modelo\n","\n","Como você está treinando um modelo muito maior e deseja readaptar os pesos pré-treinados, é importante usar uma taxa de aprendizado menor neste estágio."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtUnaz0WUDva"},"outputs":[],"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwBWy7J2kZvA"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNXelbMQtonr"},"outputs":[],"source":["len(model.trainable_variables)"]},{"cell_type":"markdown","metadata":{"id":"4G5O4jd6TuAG"},"source":["### Continue treinando o modelo\n","\n","Se você treinou para convergência anteriormente, esta etapa melhorará sua precisão em alguns pontos percentuais."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECQLkAsFTlun"},"outputs":[],"source":["fine_tune_epochs = 10\n","total_epochs =  initial_epochs + fine_tune_epochs\n","\n","history_fine = model.fit(train_dataset,\n","                         epochs=total_epochs,\n","                         initial_epoch=history.epoch[-1],\n","                         validation_data=validation_dataset)"]},{"cell_type":"markdown","metadata":{"id":"TfXEmsxQf6eP"},"source":["Vamos dar uma olhada nas curvas de aprendizado da precisão/perda de treinamento e validação ao ajustar as últimas camadas do modelo base do MobileNetV2 e treinar o classificador em cima dele. A perda de validação é muito maior do que a perda de treinamento, então você pode ter algum overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpA8PlpQKygw"},"outputs":[],"source":["acc += history_fine.history['accuracy']\n","val_acc += history_fine.history['val_accuracy']\n","\n","loss += history_fine.history['loss']\n","val_loss += history_fine.history['val_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chW103JUItdk"},"outputs":[],"source":["plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.ylim([0.8, 1])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","          plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.ylim([0, 1.0])\n","plt.plot([initial_epochs-1,initial_epochs-1],\n","         plt.ylim(), label='Start Fine Tuning')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"R6cWgjgfrsn5"},"source":["### Avaliação e previsão"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KyNhagHwfar"},"outputs":[],"source":["--------------- TODO"]},{"cell_type":"markdown","metadata":{"id":"8UjS5ukZfOcR"},"source":["E agora você está pronto para usar esse modelo para prever se seu animal de estimação é um gato ou um cachorro."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUNoQNgtfNgt"},"outputs":[],"source":["# Recupera um lote de imagens do conjunto de teste\n","image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n","predictions = model.predict_on_batch(image_batch).flatten()\n","\n","# Aplica uma função sigmoide, pois nosso modelo retorna dados em logits\n","predictions = tf.nn.sigmoid(predictions)\n","predictions = tf.where(predictions < 0.5, 0, 1)\n","\n","print('Predictions:\\n', predictions.numpy())\n","print('Labels:\\n', label_batch)\n","\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(image_batch[i].astype(\"uint8\"))\n","  plt.title(class_names[predictions[i]])\n","  plt.axis(\"off\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"17SPUdlNOBxKOJmOp1rS5wPjBygGTMDr0","timestamp":1677269041609}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}